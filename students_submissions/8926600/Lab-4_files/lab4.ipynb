{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "''' Get the data, and run a train-validation-test split. Description of each column can be found in sklearn documentation. Look at the documentation for the load_diabetes method to know what are as_frame and scaled arguments are for.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Loading Database\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "\n",
    "# Extract variable\n",
    "X = diabetes.data\n",
    "y = diabetes.target\n",
    "\n",
    "# Split Data For Operation\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a multivariate linear regression on all variables (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared is  0.5112619269090262\n",
      "MAE is  38.21668137234904\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Create and train the multivariate linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_linear = linear_model.predict(X_val)\n",
    "\n",
    "# Calculate R-squared and MAE for the linear model on the validation set\n",
    "r2_linear = r2_score(y_val, y_val_pred_linear)\n",
    "mae_linear = mean_absolute_error(y_val, y_val_pred_linear)\n",
    "print(\"***Multivariate linear regression***\")\n",
    "print(\"R-squared is \",r2_linear)\n",
    "print(\"MAE is \",mae_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a polynomial regression of the 2nd degree on the BMI feature alone (0.5 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Polynomial regression model***\n",
      "R-squared is  0.296223055272985\n",
      "MAE is  48.27302777867063\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Extracting BMI feature\n",
    "X_train_bmi = X_train[['bmi']]\n",
    "X_val_bmi = X_val[['bmi']]\n",
    "\n",
    "# Create and train the polynomial regression model on BMI\n",
    "poly_bmi_model = make_pipeline(PolynomialFeatures(degree=2, include_bias=False), LinearRegression())\n",
    "poly_bmi_model.fit(X_train_bmi, y_train)\n",
    "\n",
    "# Validations\n",
    "y_val_pred_poly_bmi = poly_bmi_model.predict(X_val_bmi)\n",
    "\n",
    "# Calculate R-squared and MAE for the polynomial model on BMI\n",
    "r2_poly_bmi = r2_score(y_val, y_val_pred_poly_bmi)\n",
    "mae_poly_bmi = mean_absolute_error(y_val, y_val_pred_poly_bmi)\n",
    "print(\"***Polynomial regression model***\")\n",
    "print(\"R-squared is \",r2_poly_bmi)\n",
    "print(\"MAE is \",mae_poly_bmi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a multivariate polynomial regression of the 2nd degree on all variables (Hint: set include_bias=False in PolynomialFeatures) (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Multivariate polynomial model***\n",
      "R-squared is  0.36717480117280155\n",
      "MAE is  42.47137889140918\n"
     ]
    }
   ],
   "source": [
    "# Create and train the multivariate polynomial regression model\n",
    "poly_model = make_pipeline(PolynomialFeatures(degree=2, include_bias=False), LinearRegression())\n",
    "poly_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred_poly = poly_model.predict(X_val)\n",
    "\n",
    "# Calculate R-squared and MAE for the multivariate polynomial model on validation set\n",
    "r2_poly = r2_score(y_val, y_val_pred_poly)\n",
    "mae_poly = mean_absolute_error(y_val, y_val_pred_poly)\n",
    "print(\"***Multivariate polynomial model***\")\n",
    "print(\"R-squared is \",r2_poly)\n",
    "print(\"MAE is \",mae_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the three models by looking at R-squared, MAPE and MAE. Explain what the values mean for a non-expert and add your insight about the values of each model. Note: You can add any further comparisons and code (this is not necessary for a perfect score, but will be reviewed and evaluated) (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multivariate Linear Regression:\n",
      "R-squared: 0.5113, MAE: 38.2167, MAPE: 0.3462\n",
      "\n",
      "Polynomial Regression on BMI:\n",
      "R-squared: 0.2962, MAE: 48.2730, MAPE: 0.4190\n",
      "\n",
      "Multivariate Polynomial Regression:\n",
      "R-squared: 0.3672, MAE: 42.4714, MAPE: 0.3809\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "# Calculate MAPE for all models on validation set\n",
    "mape_linear = mean_absolute_percentage_error(y_val, y_val_pred_linear)\n",
    "mape_poly_bmi = mean_absolute_percentage_error(y_val, y_val_pred_poly_bmi)\n",
    "mape_poly = mean_absolute_percentage_error(y_val, y_val_pred_poly)\n",
    "\n",
    "# Display results\n",
    "print(\"Multivariate Linear Regression:\")\n",
    "print(f\"R-squared: {r2_linear:.4f}, MAE: {mae_linear:.4f}, MAPE: {mape_linear:.4f}\")\n",
    "\n",
    "print(\"\\nPolynomial Regression on BMI:\")\n",
    "print(f\"R-squared: {r2_poly_bmi:.4f}, MAE: {mae_poly_bmi:.4f}, MAPE: {mape_poly_bmi:.4f}\")\n",
    "\n",
    "print(\"\\nMultivariate Polynomial Regression:\")\n",
    "print(f\"R-squared: {r2_poly:.4f}, MAE: {mae_poly:.4f}, MAPE: {mape_poly:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please answer the following questions:\n",
    "\n",
    "1.How many parameters are we fitting for each of the three models? Explain these values. Hint: for         explaining the parameters of the polynomial regression, you can use poly.get_feature_names_out() (1 point)\n",
    "\n",
    "ans.\n",
    "\n",
    "Multivariate Linear Regression:\n",
    "The number of parameters is rise to to the number of highlights also one for the caught term. In this case, it's the number of highlights within the diabetes dataset.\n",
    "\n",
    "Polynomial Regression on BMI:\n",
    "The polynomial relapse on BMI will have three parameters:\n",
    "the coefficient for BMI, the coefficient for BMI squared, and the caught term.\n",
    "\n",
    "Multivariate Polynomial Regression:\n",
    "Comparative to multivariate direct relapse, the number of parameters is decided by the number of highlights, but in this case, it's expanded due to the polynomial terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Which model would you choose for deployment, and why? (1 point)\n",
    "\n",
    "ans.\n",
    "\n",
    "The choice of the show for sending depends on different variables counting execution measurements, computational complexity, and interpretability. Here are a few contemplations:\n",
    "\n",
    "\n",
    "Multivariate Linear Regression:\n",
    "Straightforward, interpretable, and computationally effective. It may perform well in the event that the relationship between highlights and the target variable is generally straight. Be that as it may, it might battle with capturing non-linear connections.\n",
    "\n",
    "Polynomial Regression on BMI:\n",
    "On the off chance that there's prove that the relationship between BMI and the target variable is non-linear, this demonstrate can be a great choice. It features a direct number of parameters and may capture more complex designs.\n",
    "\n",
    "Multivariate Polynomial Regression:\n",
    "This model captures non-linear connections among all highlights. Be that as it may, it presents more parameters, expanding the hazard of overfitting. It can be computationally more costly and might require more information. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
